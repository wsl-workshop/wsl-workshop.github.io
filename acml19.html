<!DOCTYPE html>
<!-- saved from url=(0031)https://wsl-workshop.github.io/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Welcome to ACML2019 Weakly-supervised Learning Workshop | wsl-workshop.github.io</title>
<meta name="generator" content="Jekyll v3.8.5">
<meta property="og:title" content="Welcome to SDM2020 Weakly-supervised and Unsupervised Learning Workshop">
<meta property="og:locale" content="en_US">
<meta name="description" content="SDM2020 Weakly-supervised and Unsupervised Learning Workshop">
<meta property="og:description" content="SDM2020 Weakly-supervised and Unsupervised Learning Workshop">
<link rel="canonical" href="https://wsl-workshop.github.io/">
<meta property="og:url" content="https://wsl-workshop.github.io/">
<meta property="og:site_name" content="wsl-workshop.github.io">
<script type="application/ld+json">
{"@type":"WebSite","url":"https://wsl-workshop.github.io/","name":"wsl-workshop.github.io","headline":"Welcome to SDM2020 Weakly-supervised and Unsupervised Learning Workshop","description":"ACML19 Weakly-supervised Learning Workshop","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="./style.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">ACML2019 WSL Workshop</h1>
      <h2 class="project-tagline">Weakly-supervised Learning Workshop, Nov 17th, Nagoya, Japan
</h2>
      
      
    </section>

    <section class="main-content">
<!--       <h2 id="May 9th, Cincinnati, Ohio, United States">May 9th, Cincinnati, Ohio, United States
</h2> -->

<h1 id="topic-summary">Topic Summary</h1>

<p>UC terminates subscriptions with world’s largest scientific publisher in push for open access to publicly funded research, since “Knowledge should not be accessible only to those who can pay,” said Robert May, chair of UC’s faculty Academic Senate. Similarly, machine learning should not be accessible only to those who can pay. Specifically, modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which require a plethora of well-annotated data. Giant companies have enough money to collect well-annotated data. However, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to <strong>weakly-supervised learning (WSL)</strong>, since WSL does not require such a huge amount of annotated data. We define WSL as the collection of machine learning problem settings and algorithms that share the same goals as supervised learning but can only access to <strong>less supervised information</strong> than supervised learning. In this workshop, we discuss both theoretical and applied aspects of WSL.</p>

<p>Meanwhile, we co-organize <a href="https://www.4paradigm.com/competition/autowsl2019">AutoWSL Challenge</a> with 4Paradigm, ChaLearn and Microsoft. Winners in the competition and recived papers in WSL (related with AutoML) will be invited to <a href="http://www.cse.ust.hk/~qyaoaa/papers/TPAMI-SI-AutoML.pdf">TPAMI special issue</a>.

<h1 id="topics-of-interest">Topics of Interest</h1>

<p>WSL workshop includes but not limited to the following topics:</p>

<ul>
  <li>Theories, algorithms, and applications of <strong>incomplete supervision</strong>, e.g., semi-supervised learning, active learning and positive-unlabeled learning;</li>
  <li>Theories, algorithms, and applications of <strong>inexact supervision</strong>, e.g., multi-instance learning and complementary learning;</li>
  <li>Theories, algorithms, and applications of <strong>inaccurate supervision</strong>, e.g., crowdsourcing and learning with noisy labels;</li>
  <li>Theories, algorithms, and applications of <strong>cross-domain supervision</strong>, e.g., zero-/one-/few-shot learning, domain adaptation and multi-task leaning;</li>
  <li>Theories, algorithms, and applications of <strong>imperfect demonstration</strong>, e.g., inverse reinforcement learning and imitation learning with non-expert demonstrations;</li>
  <li>Broad applications of weakly-supervised learning, such as weakly-supervised <strong>object detection</strong>, weakly-supervised <strong>sequence modeling</strong>, weakly-supervised <strong>cross-media retrieval</strong>, and weakly-supervised <strong>medical image segmentation</strong>.</li>
</ul>

<h1 id="topic-description">Topic Description</h1>

<p>The focus of this workshop is three classical types of weak supervision: incomplete supervision, inexact supervision and inaccurate supervision. Specifically, incomplete supervision considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised learning and positive-unlabeled learning. Inexact supervision considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, multi-instance learning belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. Inaccurate supervision considers the situation where the supervision information is not always the ground-truth, such as learning with noisy labels.</p>

<p>Moreover, this workshop covers two emerging types of weak supervision: cross-domain supervision and imperfect demonstration.
Cross-domain supervision considers the situation where the supervision information is scarce or even non-existent in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain. Imperfect demonstration considers the situation for inverse reinforcement learning and imitation learning, where the agent learns with imperfect or non-expert demonstrations. For example, AlphaGo learns a policy from a sequence of states and actions (expert demonstration). Even if an expert player (human or agent) wins a game, it is not guaranteed that every action in the sequence is optimal.</p>

<p>This workshop will discuss the fundamental theory of weakly-supervised learning. Although theories of statistical weakly-supervised learning already exist, extending these results for deep weakly-supervised learning is still a challenge. Besides, this workshop also discusses on broad applications of weakly-supervised learning, such as weakly-supervised object detection (computer vision),
weakly-supervised sequence modeling (natural language processing), weakly-supervised cross-media retrieval (information retrieval),
and weakly-supervised medical image segmentation (healthcare).</p>

<h1 id="submission-guidelines">Submission Guidelines</h1>

<p>Workshop submissions and camera ready versions will be handled by Gmail. Please E-mail your paper to wsl.workshop@gmail.com with subject line ACML19-WSL-{paper name}. Papers should be formatted according to the ACML19 formatting instructions for the Conference Track. The submissions with 2 pages will be considered for the poster, while the submissions with at least 4 pages will be considered for the oral presentation.</p>

<p>ACML19-WSL is a non-archival venue and there will be no published proceedings. The papers will be posted on the workshop website. It will be possible to submit to other conferences and journals both in parallel to and after ACML19-WSL. Besides, we also welcome submissions to ACML19-WSL that are under review at other conferences and workshops. At least one author from each accepted paper must register for the workshop. Please see the ACML 2019 Website for information about accommodation and registration.</p>

<h1 id="invited-speakers">List of Invited Speakers</h1>

<p><a href="http://www.cse.ust.hk/~jamesk/">James T. Kwok</a>, Hong Kong University of Science and Technology (confirmed)</p>
<p><a href="https://www.csie.ntu.edu.tw/~htlin/">Hsuan-Tien Lin</a>, National Taiwan University (confirmed)</p>
<p><a href="http://lamda.nju.edu.cn/liyf/">Yu-Feng Li</a>, Nanjing University (confirmed)</p>

<h1 id="tentative-schedule">Tentative Schedule</h1>

<p>The workshop will be combined with invited talks, accepted presentations, and informal discussions.</p>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Event</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>13:30-13:35</td>
      <td><strong>Opening Ceremony</strong></td>
    </tr>
    <tr>
      <td>13:35-14:05</td>
      <td><strong>Keynote Talk 1</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Multilabel Learning with Global and Local Label Correlation</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: <a href="http://www.cse.ust.hk/~jamesk/">James T. Kwok</a>, (Hong Kong University of Science and Technology)</td>
    </tr><tr>
      <td>14:05-14:15</td>
      <td><strong>Contributed Talk 1</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Projected BNNs: Avoiding Weight-space Pathologies by Learning Latent Representations of Neural Network Weights</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Melanie F. Pradier (Harvard University)</td>
    </tr>
    <tr>
      <td>14:15-14:45</td>
      <td><strong>Keynote Talk 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Safe Semi-supervised Learning</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: <a href="http://lamda.nju.edu.cn/liyf/">Yu-Feng Li</a>, (Nanjing University)</td>
    </tr>
    <tr>
      <td>14:45-14:55</td>
      <td><strong>Contributed Talk 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Towards Automated Learning from Noisy Labels</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Hansi Yang (Tsinghua University)</td>
    </tr>
	<tr>
      <td>14:55-15:25</td>
      <td><strong>Keynote Talk 3</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Making Active Learning More Realistic</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: <a href="http://lamda.nju.edu.cn/liyf/">Hsuan-Tien Lin</a>, (National Taiwan University)</td>
    </tr>
    <tr>
      <td>15:25-15:35</td>
      <td><strong>Contributed Talk 3</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Mitigating Overfitting in Supervised Classification from Two Unlabeled Datasets: A Consistent Risk Correction Approach</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Nan Lu (The University of Tokyo)</td>
    </tr>
	<tr>
      <td>15:35-16:05</td>
      <td><strong>AutoWSL Challenge Talk</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: AutoWSL Challenge & Results</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Speaker</strong>: Xiawei Guo</td>
    </tr>
	<tr>
      <td>16:05-16:30</td>
      <td><strong>Panel Discussion & Concluding Remark</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Host</strong>: Bo Han</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Guests</strong>: Masashi Sugiyama, James T. Kwok, Hsuan-Tien Lin, Yu-Feng Li, Gang Niu and Quanming Yao</td>
    </tr>
  </tbody>
</table>

<h1 id="Best-paper">Best Paper Awards (alphabetic ordering)</h1>

<p>Nan Lu, Tianyi Zhang, Gang Niu, and Masashi Sugiyama. RIKEN AIP & The University of Tokyo, Japan.</p>

<p>Melanie F. Pradier, Weiwei Pan, Jiayu Yao, Soumya Ghosh, and Finale Doshi-Velez. Harvard University, USA.</p>

<p>Hansi Yang, and Quanming Yao. Tsinghua University & 4Paradigm, China.</p>

<h1 id="important-dates">Important Dates</h1>

<p>Submission Deadline: 05:00 PM (Pacific Time), Oct 5th, 2019 (2nd Round)</p>

<p>Acceptance Notifications: Oct 10th, 2019</p>

<h1 id="organizers">Organizers</h1>

<p><a href="https://bhanml.github.io/">Bo Han</a>, RIKEN AIP, Japan.</p>

<p><a href="https://niug1984.github.io/">Gang Niu</a>, RIKEN AIP, Japan.</p>

<p><a href="http://www.cse.ust.hk/~qyaoaa/">Quanming Yao</a>, 4Paradigm Inc., Hong Kong.</p>

<p><a href="https://giorgiop.github.io/">Giorgio Patrini</a>, DeepTrace Inc., Netherlands.</p>

<p><a href="https://akmenon.github.io/">Aditya Krishna Menon</a>, Google AI, USA.</p>

<p><a href="http://web.eecs.umich.edu/~cscott/">Clayton Scott</a>, University of Michigan, USA.</p>

<p><a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">Masashi Sugiyama</a>, RIKEN / University of Tokyo, Japan.</p>

<h1 id="sponsors">Sponsors</h1>

<p>Several awards are kindly sponsored by <a href="https://www.4paradigm.com/">4Paradigm</a>. We have supported best paper awards and travel awards.</p>

      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  

</body></html>

