<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Imperfect Information Learning Software</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css">
  </head>

 <body>
    <section class="page-header">
      <h1 class="project-name">Imperfect Information Learning Software</h1>
      <h2 class="project-tagline">Partially from Imperfect Information Learning Team, RIKEN Center for Advanced Intelligence Project</h2>
    </section>

<section class="main-content">

<h1>Overview</h1>
    <p>There should be an overview.</p>
    <p><a href="#weaklysupervised">weakly supervised learning</a></p>
    <p><a href="#labelnoise">label-noise learning</a></p>
    <p><a href="#adversarial">adversarial training</a></p>
    <p><a href="#other">other</a></p>
    
<h1 id="weaklysupervised">Weakly supervised learning</h1>
    <ul>
        <li><p><a href="https://github.com/alonjacovi/document-set-expansion-pu" target="_blank">
        Scalable evaluation and improvement of document set expansion via neural positive-unlabeled learning</a> (EACL 2021)</p></li>
        
        <li><p><a href="https://github.com/leishida/Um-Classification" target="_blank">
        Binary Classification from multiple unlabeled datasets via surrogate set classification</a> (ICML 2021)</p></li>
        
        <li><p>Learning from similarity-confidence data (ICML 2021)</p></li>
        
        <li><p><a href="https://lfeng-ntu.github.io/Codes/Pcomp.zip" target="_blank">
        Pointwise binary classification with pairwise confidence comparisons</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://lfeng-ntu.github.io/Codes/SDMIL.zip" target="_blank">
        Multiple-instance learning from similar and dissimilar bags</a> (KDD 2021)</p></li>
    </ul>

<h1 id="labelnoise">Label-noise learning</h1>
    <ul>
        <li><p><a href="https://github.com/QizhouWang/instance-dependent-label-noise" target="_blank">
        Tackling instance-dependent label noise via a universal probabilistic model</a> (AAAI 2021)</p></li>
        
        <li><p>Class2Simi: A noise reduction perspective on learning with noisy labels (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/antoninbrthn/CSIDN" target="_blank">
        Confidence scores make instance-dependent label-noise learning possible</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/YivanZhang/lio" target="_blank">
        Learning noise transition matrix from only noisy labels via total variation regularization</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/xuefeng-li1/Provably-end-to-end-label-noise-learning-without-anchor-points" target="_blank">
        Provably end-to-end label-noise learning without anchor points</a> (ICML 2021)</p></li>
        
        <li><p>Instance-dependent label-noise learning under a structural causal model (NeurIPS 2021)</p></li>
        
        <li><p><a href="https://github.com/tmllab/PES" target="_blank">
        Understanding and improving early stopping for learning with noisy labels</a> (NeurIPS 2021)</p></li>
    </ul>

<h1 id="#adversarial">Adversarial training</h1>
    <ul>
        <li><p><a href="https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training" target="_blank">
        Geometry-aware instance-reweighted adversarial training</a> (ICLR 2021)</p></li>
        
        <li><p><a href="https://github.com/HanshuYAN/CIFS" target="_blank">
        CIFS: Improving adversarial robustness of CNNs via channel-wise Importance-based feature selection</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/d12306/dsnet" target="_blank">
        Learning diverse-structured networks for adversarial robustness</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/fengliu90/SAMMD" target="_blank">
        Maximum mean discrepancy is aware of adversarial attacks</a> (ICML 2021)</p></li>
        
        <li><p><a href="https://github.com/QizhouWang/MAIL" target="_blank">
        Probabilistic margins for instance reweighting in adversarial training</a> (NeurIPS 2021)</p></li>
        
        <li><p><a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">
            Attacks Which Do Not Kill Training Make Adversarial Learning Stronger</a> (ICML 2020)</p></li>
    </ul>

<h1 id="#other">Other</h1>
    <ul>
        <li><p>Large-margin contrastive learning with distance polarization regularizer (ICML 2021)</p></li>
    </ul>





</section>
</body></html>
