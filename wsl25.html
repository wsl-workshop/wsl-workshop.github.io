<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>WSL Workshop 2025</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css">
    <style>
        .page-header {
            background-image: url("nanjing.jpg");
            background-size: cover;
        }
    </style>
  </head>

<script type="text/javascript">
var myStartDate = "2023-11-23T"
var myEndDate = "2023-11-24T"
var myStartTime = "09:30"
var myEndTime = "17:00"
var myTimeZone = "+09:00"

var myStartTime = new Date(myStartDate + myStartTime + ":00.000" + myTimeZone);
var myEndTime = new Date(myEndDate + myEndTime + ":00.000" + myTimeZone);
var myRefTime = new Date(myStartDate + "00:00:00.000" + myTimeZone);

function getTimezone() {
  var offset = -(new Date()).getTimezoneOffset()/60;
  return ("UTC" + (offset >= 0 ? "+" : "") + offset);
}

function getLocalTimezone() {
  try {
    return Intl.DateTimeFormat().resolvedOptions().timeZone + " time (" + getTimezone() + ", your browser's time zone)";
  }
  catch(e) {
    return " (" + getTimezone() + ", i.e., your browser's time zone)";
  }
}

function displayTime(dt) {
  var hour = dt.getHours();
  var minute = dt.getMinutes();
  var temp = '' + ((hour < 10) ? '0' : '') + hour;
  temp += ((minute < 10) ? ':0' : ':') + minute;
  return temp;
}

function writeTimeRange(startHour, startMin, endHour, endMin) {
  var oneMin = 1000 * 60;
  var oneHour = oneMin * 60;
  var startTime = new Date(myRefTime.getTime() + startHour * oneHour + startMin * oneMin);
  var endTime = new Date(myRefTime.getTime() + endHour * oneHour + endMin * oneMin);
  document.write(displayTime(startTime));
  document.write(" -- ");
  if (endTime.getDay() != myStartTime.getDay()) {
    document.write(myEndTime.toLocaleDateString('en-US', {month:'short', day:'numeric'}));
	document.write(" ");
  }
  document.write(displayTime(endTime));
  return;
}
</script>


 <body>
    <section class="page-header">
      <h1 class="project-name">International Workshop on</h1>
      <h1 class="project-name">Weakly Supervised Learning 2025</h1>
      <h2 class="project-tagline" style="font-size:175%;">Southeast University; Oct 27 to 29, China Standard Time (UTC+8)</h2>
      <h2 class="project-tagline">&nbsp;</h2>
    </section>

<section class="main-content">
    <center>[ <a href="#program">Program</a>,
			<a href="#registration">Registration</a>,
              <a href="#topics">Topics</a>,
              <a href="#organizers">Organizers</a>,
              <a href="#previous-workshops">Previous Workshops</a> ]</center>

<p>This is an international workshop on weakly supervised learning. The main goal of this workshop is to discuss challenging research topics in weakly supervised learning areas such as semi-supervised learning, positive-unlabeled learning, label noise learning, partial label learning, and self-supervised learning, as well as the foster collaborations among universities and institutes.</p>

 

<h1 id="program">Program</h1>

	<h2>Venue & Date</h2>
        <p><b>Workshop Venue:</b> Holiday Inn Nanjing Qinhuai South, Nanjing, China. </p>
		<p><b>Workshop Date:</b> October 27, 09:30--17:00, October 28, 09:30--16:00, October 29, 09:30--16:30 (China Standard Time (UTC+8)).</p>


	<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d3388.355792525452!2d118.8297784!3d31.869741!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x35b585295c16ee7b%3A0x7a8f725fcbcb5182!2sHoliday%20Inn%20NANJING%20QINHUAI%20SOUTH!5e0!3m2!1sen!2s!4v1751278827058!5m2!1sen!2s" width="800" height="600" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
		<p><b>Banquet Date:</b> October 28 17:30 - (China Standard Time (UTC+8)).</p>
		<!--<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d5893.809421946069!2d153.09395947706602!3d-27.584672176253072!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x6b9145d78e25c0bd%3A0xa90e3efb0f183b07!2s3%20Bamboo%20Seafood%20Restaurant!5e1!3m2!1sen!2sau!4v1731983931323!5m2!1sen!2sau" width="800" height="600" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>-->

    <h2>Schedule</h1>
        <p>The workshop will use 
        China Standard Time (UTC+8)
         for scheduling, and it will be combined with invited talks and contributed talks.</p>
		<p>URL for Online Attending: <a href=""></a></p>
<!--<table>
  <thead>
    <tr><th style="width:25ex">Time</th><th>Event</th></tr>
  </thead>
  <tbody>
    <tr><td><b>November 26 (Day 1)</b></td></tr>
    <tr><td>09:30 -- 09:45</td><td><b>Opening and Welcome Remarks</b><br><b>Hosts</b>: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a> (RIKEN/ The University of Tokyo) and <a href="https://mxuq.github.io/" target="_blank">Miao Xu </a> (The University of Queensland)</td></tr>
    <tr><td>09:45 -- 10:25</td><td><b>Title</b>: The evolving role of human supervision in modern AI systems<br><b>Speaker</b>: <a href="https://takashiishida.github.io/" target="_blank">Takashi Ishida</a> (RIKEN / The University of Tokyo)</td></tr>
    <tr><td>10:25 -- 10:55</td><td><b>Coffee Break</b></td></tr>
    <tr><td>10:55 -- 11:35</td><td><b>Title</b>: Handling Out-of-Distribution Data in Graph with Inexact Supervision<br><b>Speaker</b>: <a href="https://ruihongqiu.github.io/" target="_blank">Ruihong Qiu</a> (The University of Queensland)</td></tr>
    <tr><td>11:35 -- 12:15</td><td><b>Title</b>: Weakly Supervised Learning from a Contamination-Decontamination Perspective<br><b>Speaker</b>: <a href="https://scholar.google.com/citations?user=pBQgK_YAAAAJ&hl=en" target="_blank">Chao-Kai Chiang</a> (The University of Tokyo)</td></tr>
    <tr><td>12:15 -- 13:45</td><td><b>Lunch Break</b></td></tr>
    <tr><td>13:45 -- 14:25</td><td><b>Title</b>: Generalizing Importance Weighting to a Universal Solver for Distribution Shift Problems<br><b>Speaker</b>: <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a> (RIKEN)</td></tr>
    <tr><td>14:25 -- 15:05</td><td><b>Title</b>: Learning from Imperfect Demonstrations in Visual Navigation<br><b>Speaker</b>: <a href="https://about.uq.edu.au/experts/43887" target="_blank">Heming Du</a> (The University of Queensland)</td></tr>
    <tr><td>15:05 -- 15:35</td><td><b>Coffee Break</b></td></tr>
    <tr><td>15:35 -- 16:15</td><td><b>Title</b>: Adaptive Learning in Non-stationary Environments<br><b>Speaker</b>: <a href="https://zhangzy07.github.io/" target="_blank">Zhen-Yu Zhang</a> (RIKEN)</td></tr>
    <tr><td>16:15 -- 16:55</td><td><b>Title</b>: Sign Language Translation with Weak Supervision<br><b>Speaker</b>: <a href="https://sites.google.com/view/xinyus-homepage/Home" target="_blank">Xin Yu</a> (The University of Queensland/Google) </td></tr>

    <tr><td><b>November 27 (Day 2)</b></td></tr>
    <tr><td>09:30 -- 10:10</td><td><b>Title</b>: Instinct, Evolution, Creativity: New AI Abilities Brought by Learngene<br><b>Speaker</b>: <a href="http://palm.seu.edu.cn/xgeng/" target="_blank">Xin Geng</a> (Southeast University)</td></tr>
    <tr><td>10:10 -- 10:40</td><td><b>Coffee Break</b></td></tr>
    <tr><td>10:40 -- 11:20</td><td><b>Title</b>: Robust Loss Functions for Training Decision Trees with Noisy Labels<br><b>Speaker</b>: <a href="https://www.cyber.uq.edu.au/profile/574/jonathan-wilton"  target="_blank">Jonathan Wilton </a> (The University of Queensland)</td></tr>
    <tr><td>11:20 -- 12:00</td><td><b>Title</b>: Exploring Insights with Partial Labels<br><b>Speaker</b>: <a href="https://lvjiaqi77.github.io/" target="_blank">Jiaqi Lv </a> (Southeast University)</td></tr>
    <tr><td>12:00 -- 13:30</td><td><b>Lunch Break</b></td></tr>
    <tr><td>13:30 -- 14:10</td><td><b>Title</b>: Robust Self-Supervised Learning with Applications in Multiple Domains<br><b>Speaker</b>: <a href="https://shuochenya.github.io/"  target="_blank">Shuo Chen</a> (RIKEN)</td></tr>
    <tr><td>14:10 -- 14:50</td><td><b>Title</b>: Model-Based Methods for Learning with Noisy Labels<br><b>Speaker</b>: <a href="https://a5507203.github.io/"  target="_blank">Yu Yao</a> (The University of Sydney)</td></tr>
    <tr><td>14:50 -- 15:20</td><td><b>Coffee Break</b></td></tr>
    <tr><td>15:20 -- 16:00</td><td><b>Title</b>: Robust Imitation Learning with Imperfect Demonstrations<br><b>Speaker</b>: <a href="https://yunke-wang.github.io/" target="_blank">Yunke Wang</a> (The University of Sydney)</td></tr>
    <tr><td>16:00 --</td><td><b>Transfer to Banquet Place</b></td></tr>
    <tr><td>17:45 --</td><td><b>Banquet</b></td></tr>

    <tr><td><b>November 28 (Day 3)</b></td></tr>
    <tr><td>09:30 -- 10:10</td><td><b>Title</b>: Revealing causal information from data<br><b>Speaker</b>: <a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</a> (The University of Sydney)</td></tr>
    <tr><td>10:10 -- 10:50</td><td><b>Title</b>: Maximizing Data Efficiency in an Open World<br><b>Speaker</b>: <a href="https://luoyadan.github.io/"  target="_blank">Yadan Luo</a> (University of Queensland)</td></tr>
    <tr><td>10:50 -- 11:20</td><td><b>Coffee Break</b></td></tr>
    <tr><td>11:20 -- 12:00</td><td><b>Title</b>: Exploring Trustworthy Foundation Models under Imperfect Data<br><b>Speaker</b>: <a href="https://bhanml.github.io/" target="_blank">Bo Han</a> (Hong Kong Baptist University)</td></tr>
    <tr><td>12:00 -- 12:40</td><td><b>Title</b>: A Boosting Framework for Positive-Unlabelled Learning<br><b>Speaker</b>: <a href="https://eecs.uq.edu.au/profile/5606/yawen-zhao"  target="_blank">Yawen Zhao</a> (University of Queensland)</td></tr>
    <tr><td>12:40 -- 14:10</td><td><b>Lunch Break</b></td></tr>
    <tr><td>14:10 -- 14:50</td><td><b>Title</b>: Revisiting Multi-Instance Learning: Beyond Attention<br><b>Speaker</b>: <a href="https://www.weijiazhangxh.com/" target="_blank">Weijia Zhang</a> (The University of Newcastle )</td></tr>
    <tr><td>14:50 -- 15:30</td><td><b>Title</b>: Machine Unlearning with Varying Levels of Data Imperfection<br><b>Speaker</b>: Shaofei Shen (University of Queensland)</td></tr>
    <tr><td>15:30 -- 16:00</td><td><b>Coffee Break</b></td></tr>
    <tr><td>16:00 -- 16:30</td><td><b>Closing Remarks and Discussion</b><br><b>Host</b>: <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a> (RIKEN)</td></tr>
  </tbody>
</table>-->

	
<!-- <table>
  <thead>
    <tr><th style="width:25ex">Time</th><th>Event</th></tr>
  </thead>
  <tbody>
  <tr><td><b>November 23</b></td></tr>
    <tr><td>09:30 -- 09:35<noscript>09:30 -- 09:35</noscript></td>
        <td><b>Opening Ceremony</b></td></tr>
    <tr><td></td><td><b>Host</b>: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a> (RIKEN / The University of Tokyo)</td></tr>
    
     <tr><td>09:35 -- 10:35<noscript>09:35 -- 10:35</noscript></td>
        <td><b>Session 1 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Enhancing Language Models through Improved Pre-Training and Fine-Tuning<br>
        <b>Speaker</b>: <a href="https://www.cse.ust.hk/~jamesk/" target="_blank">James Tin Yau Kwok</a> (Hong Kong University of Science and Technology)</td></tr>
    <tr><td></td><td><b>Title</b>: The "Gene" of Machine Learning: Make Machines Learn Like Humans<br>
        <b>Speaker</b>: <a href="http://palm.seu.edu.cn/xgeng/" target="_blank">Xin Geng</a> (Southeast University)</td></tr>

    <tr><td>10:35 -- 10:55<noscript>10:35 -- 10:55</noscript></td>
        <td><b>Bio Breaks and Social</b></td></tr>
    
     <tr><td>10:55 -- 11:55<noscript>10:55 -- 11:55</noscript></td>
        <td><b>Session 2 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Towards Safe Abductive Learning with Weak Label and Weak Rules<br>
        <b>Speaker</b>: <a href="https://cs.nju.edu.cn/liyf/index.htm" target="_blank">Yu-Feng Li</a> (Nanjing University)</td></tr>
    <tr><td></td><td><b>Title</b>: Visual Recovery towards Understanding<br>
        <b>Speaker</b>: <a href="http://changxu.xyz/" target="_blank">Chang Xu</a> (The University of Sydney)</td></tr>
		
	<tr><td>12:00 -- 13:00<noscript>12:00 -- 13:00</noscript></td>
        <td><b>Lunch Time</b></td></tr>
    
     <tr><td>13:00 -- 14:00<noscript>13:00 -- 14:00</noscript></td>
        <td><b>Session 3 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Late stopping for weakly supervised learning<br>
        <b>Speaker</b>: <a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</a> (The University of Sydney)</td></tr>
    <tr><td></td><td><b>Title</b>: Open-World Learning: Challenges and Solutions<br>
        <b>Speaker</b>: <a href="https://gcatnjust.github.io/ChenGong/index.html" target="_blank">Chen Gong</a> (Nanjing University of Science and Technology)</td></tr>
		
	<tr><td>14:00 -- 14:20<noscript>14:00 -- 14:20</noscript></td>
        <td><b>Bio Breaks and Social</b></td></tr>
    
     <tr><td>14:20 -- 15:50<noscript>14:20 -- 15:50</noscript></td>
        <td><b>Session 4 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Exploring Trustworthy Machine Learning under Imperfect Data<br>
        <b>Speaker</b>: <a href="https://bhanml.github.io/" target="_blank">Bo Han</a> (Hong Kong Baptist University)</td></tr>
    <tr><td></td><td><b>Title</b>: Label-Agnostic Unlearning in Deep Models<br>
        <b>Speaker</b>: <a href="https://researchers.uq.edu.au/researcher/26509" target="_blank">Miao Xu</a> (The University of Queensland)</td></tr>
    <tr><td></td><td><b>Title</b>: An Information-Theoretic Analysis of Learning under General Data Corruption<br>
        <b>Speaker</b>: <a href="https://scholar.google.com/citations?user=KQUQlG4AAAAJ&hl=en" target="_blank">Nan Lu</a> (The University of TÃ¼bingen)</td></tr>
		
	<tr><td>15:50 -- 16:10<noscript>15:50 -- 16:10</noscript></td>
        <td><b>Bio Breaks and Social</b></td></tr>
    
     <tr><td>16:10 -- 17:10<noscript>16:10 -- 17:10</noscript></td>
        <td><b>Session 5 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Robust Contrastive Learning and Its Applications<br>
        <b>Speaker</b>: <a href="https://sites.google.com/view/shuochen/" target="_blank">Shuo Chen</a> (RIKEN)</td></tr>
	<tr><td></td><td><b>Title</b>: Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification<br>
        <b>Speaker</b>: <a href="https://takashiishida.github.io/" target="_blank">Takashi Ishida</a> (RIKEN / The University of Tokyo)</td></tr>
	<tr><td>17:10 -- 18:00<noscript>17:10 -- 18:00</noscript></td>
        <td><b>Open Discussion</b></td></tr>
	<tr><td>18:00 -- 20:30<noscript>18:00 -- 20:00</noscript></td>
        <td><b>Closed Discussion / Dinner</b></td></tr>
		
		
	<tr><td><b>November 24</b></td></tr>
	<tr><td>09:30 -- 10:30<noscript>09:30 -- 10:30</noscript></td>
        <td><b>Session 1 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Emerging Drug Interaction Prediction from Biomedical Network<br>
        <b>Speaker</b>: <a href="https://lars-group.github.io/" target="_blank">Quanming Yao</a> (Tsinghua University)</td></tr>
    <tr><td></td><td><b>Title</b>: Domain Generalization via Content Factors Isolation: A Two-level Latent Variable Modelling Approach<br>
        <b>Speaker</b>: <a href="https://mingming-gong.github.io/" target="_blank">Mingming Gong</a> (The University of Melbourne)</td></tr>
		
	<tr><td>10:30 -- 10:50<noscript>10:30 -- 10:50</noscript></td>
        <td><b>Bio Breaks and Social</b></td></tr>
    
     <tr><td>10:50 -- 11:50<noscript>10:50 -- 11:50</noscript></td>
        <td><b>Session 2 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models<br>
        <b>Speaker</b>: <a href="http://www.yliuu.com/" target="_blank">Yang Liu</a> (University of California, Santa Cruz)</td></tr>
    <tr><td></td><td><b>Title</b>: Towards Robust Foundation Models: Adversarial Contrastive Learning<br>
        <b>Speaker</b>: <a href="https://zjfheart.github.io/" target="_blank">Jingfeng Zhang</a> (The University of Auckland)</td></tr>
		
	<tr><td>11:50 -- 13:00<noscript>11:50 -- 13:00</noscript></td>
        <td><b>Lunch Time</b></td></tr>
    
     <tr><td>13:00 -- 14:00<noscript>13:00 -- 14:00</noscript></td>
        <td><b>Session 3 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Towards Continuous Adaptation in Non-stationary Environments<br>
        <b>Speaker</b>: <a href="https://zhangzy07.github.io/" target="_blank">Zhen-Yu Zhang</a> (RIKEN)</td></tr>
    <tr><td></td><td><b>Title</b>: Towards Robust Deep Learning under Distribution Shift: an Importance Weighting Approach<br>
        <b>Speaker</b>: <a href="https://scholar.google.com/citations?user=XZIPnxIAAAAJ&hl=en" target="_blank">Tongtong Fang</a> (The University of Tokyo)</td></tr>
		
	<tr><td>14:00 -- 14:20<noscript>14:00 -- 14:20</noscript></td>
        <td><b>Bio Breaks and Social</b></td></tr>
    
     <tr><td>14:20 -- 15:20<noscript>14:20 -- 15:20</noscript></td>
        <td><b>Session 4 (25min talk + 5min Q&A for each speaker)</b></td></tr>
    <tr><td></td><td><b>Title</b>: Weakly Supervised Disentanglement<br>
        <b>Speaker</b>: <a href="https://yivan.xyz/about" target="_blank">Yivan Zhang</a> (The University of Tokyo)</td></tr>
    <tr><td></td><td><b>Title</b>: On the Relation between Complementary-Label Learning and Negative-Unlabeled Learning<br>
        <b>Speaker</b>: <a href="https://wwangwitsel.github.io/" target="_blank">Wei Wang</a>  (The University of Tokyo)</td></tr>
		
	 <tr><td>15:20 -- 16:00<noscript>15:20 -- 16:00</noscript></td>
        <td><b>Closing Ceremony</b></td></tr>
    <tr><td></td><td><b>Host</b>: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a> (RIKEN / The University of Tokyo)</td></tr>
		
  </tbody>
</table>-->

<h1 id="registration">Registration</h1>
    <p><font color='FF0000'>The registration link will be available soon.</font> The registration fee is approximately USD 220 (or equivalent in CNY), including lunches and coffee breaks for all three days. </p>
	<p> Note: We are working on the payment arrangements for international participants - detailed payment instructions will be provided shortly.
    </p>

<h1 id="topics">Topics</h1>

    <h2>Overview</h2>
        <p>Machine learning should not be accessible only to those who can pay. Specifically, modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which require a plethora of well-annotated data. Giant companies have enough money to collect well-annotated data. However, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to <b>weakly supervised learning (WSL)</b>, since WSL does not require such a huge amount of annotated data. We define WSL as the collection of machine learning problem settings and algorithms that share the same goals as supervised learning but can only access to <b>less supervised information</b> than supervised learning. In this workshop, we discuss both theoretical and applied aspects of WSL.</p>

        <p>This workshop is a series of our previous workshops at ACML 2019, SDM 2020, ACML 2020, IJCAI 2021, and ACML 2021. Our particular technical emphasis at this workshop is incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and weak adversarial supervision. Meanwhile, this workshop will also focus on <b>WSL for Science and Social Good</b>, such as WSL for COVID-19, WSL for healthcare, WSL for climate change, WSL for remote sensing, and new public WSL datasets regarding the scientific scenarios. </p>

    <h2>Topics of Interest</h2>
        <p>WSL workshop includes (but not limited to) the following topics:</p>
        <ul>
            <li>Algorithms and theories of <b>incomplete supervision</b>, e.g., semi-supervised learning, active learning, and positive-unlabeled learning;</li>
            <li>Algorithms and theories of <b>inexact supervision</b>, e.g., multi-instance learning, complementary learning, and open-set learning;</li>
            <li>Algorithms and theories of <b>inaccurate supervision</b>, e.g., crowdsourced learning and label-noise learning;</li>
            <li>Algorithms and theories of <b>cross-domain supervision</b>, e.g., zero-/one-/few-shot learning, transferable learning, and multi-task learning;</li>
            <li>Algorithms and theories of <b>imperfect demonstration</b>, e.g., inverse reinforcement learning and imitation learning with non-expert demonstrations;</li>
            <li>Algorithms and theories of <b>adversarial</b> weakly-supervised learning, e.g., adversarial semi-supervised learning and adversarial label-noisy learning; </li>
			<li>Algorithms and theories of <b>self-supervision</b>, e.g., contrastive learning and autoencoder learning; </li>
            <li>Broad applications of weakly supervised learning in the field of computer science, such as weakly supervised object detection <b>(computer vision)</b>, weakly supervised sequence modeling <b>(natural language processing)</b>, and weakly supervised cross-media retrieval <b>(information retrieval)</b>.</li>
            <li><b>WSL for science and social good</b>, such as WSL for COVID-19, WSL for healthcare, WSL for climate change, and WSL for remote sensing, meanwhile, new public datasets regarding the above WSL research directions (new focus).</li>
        </ul>

    <h2>Further Descriptions</h2>
        <p>The focus of this workshop is six types of weak supervision: incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and weak adversarial supervision, which are briefly introduced below. </p>

	 <ul>
        <li><b>Incomplete supervision</b> considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised learning and positive-unlabeled learning. </li>

        <li><b>Inexact supervision</b> considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, multi-instance learning belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. </li>
        
        <li><b>Inaccurate supervision</b> considers the situation where the supervision information is not always the ground-truth, such as label-noise learning.</li>

        <li><b>Cross-domain supervision</b> considers the situation where the supervision information is scarce or even non-existent in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain. </li>

        <li><b>Imperfect demonstration</b> considers the situation for inverse reinforcement learning and imitation learning, where the agent learns with imperfect or non-expert demonstrations. For example, AlphaGo learns a policy from a sequence of states and actions (expert demonstration). Even if an expert player wins a game, it is not guaranteed that every action in the sequence is optimal.</li>

        <li><b>Weak adversarial supervision</b> considers the situation where weak supervision meets adversarial robustness. Since machine learning models are increasingly deployed in real-world applications, their security attracts more and more attention from both academia and industry. Therefore, many robust learning algorithms aim to prevent various evasion attacks, e.g., adversarial attacks, privacy attacks, model stealing attacks, and so on. However, almost all those robust algorithms (against evasion attacks) implicitly assume the strong supervision signals (no noisy labels in the training data), which hardly meets the requirements in practice. Therefore, when we develop evasion-robust algorithms, it is very practical/urgent to consider the supervision signals are imperfect.</li>

	<li><b>Self-supervision</b> considers the unsupervised situation, and it pre-trains a generic feature representation by autonomously building the pseudo supervision (e.g., the similarity contrast and sample reconstruction) from the raw data, the learned representation can be applied in various downstream tasks such as classification, retrieval, and clustering.</li>
	 </ul>
		
        <p>Meanwhile, this workshop will <b>continue discussing broad applications of weakly supervised learning in the field of computer science</b>, such as weakly supervised object detection (computer vision), weakly supervised sequence modeling (natural language processing), and weakly supervised cross-media retrieval (information retrieval).</p>


<h1 id="organizers">Organizers</h1>
	<h2>General Chair</h2>
		<p><a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>, RIKEN / The University of Tokyo, Japan.</p>
        <p><a href="http://palm.seu.edu.cn/xgeng/" target="_blank">Xin Geng</a>, Southeast University, China.</td></tr></p>
    <h2>Program Chair</h2>
        <p><a href="https://lvjiaqi77.github.io/" target="_blank">Jiaqi Lv </a>, Southeast University, China.</td></tr></p>
    <h2>Program Co-Chairs</h2>
        <p><a href="https://miaoxu-ml.github.io/index.html" target="_blank">Miao Xu</a>, The University of Queensland, Australia.</p>
		<p><a href="https://bhanml.github.io/" target="_blank">Bo Han</a>, Hong Kong Baptist University, Hong Kong SAR, China.</p>
        <p><a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</a>, The University of Sydney, Australia.</p>
        <p><a href="https://niug1984.github.io/" target="_blank">Gang Niu</a>, RIKEN, Japan.</p>
	<p><a href="https://lfeng1995.github.io/" target="_blank">Lei Feng</a>, Southeast University, China.</p>


<h1 id="previous-workshops">Previous Workshops</h1>
    <p><a href="https://wsl-workshop.github.io/wsl24.html" target="_blank">WSL 2024 Workshop</a>, Brisbane, Australia.</p> 
	<p><a href="https://wsl-workshop.github.io/wsl23.html" target="_blank">WSL 2023 Workshop</a>, Tokyo, Japan.</p> 
	<p><a href="https://wsl-workshop.github.io/acml22.html" target="_blank">ACML2022 WSL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/acml21.html" target="_blank">ACML2021 WSL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/ijcai21.html" target="_blank">IJCAI2021 WSRL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/acml20.html" target="_blank">ACML2020 WSRL Workshop</a>, Online.</p>
    <p><a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">SDM2020 WSUL Workshop</a>, Ohio, United States.</p>
    <p><a href="https://wsl-workshop.github.io/acml19.html" target="_blank">ACML2019 WSL Workshop</a>, Nagoya, Japan.</p>

<footer class="site-footer">
    <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
</footer>
</section>
</body></html>
