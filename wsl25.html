<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>WSL Workshop 2025</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css">
    <style>
        .page-header {
            background-image: url("nanjing.jpg");
            background-size: cover;
        }
    </style>
  </head>

<script type="text/javascript">
var myStartDate = "2023-11-23T"
var myEndDate = "2023-11-24T"
var myStartTime = "09:30"
var myEndTime = "17:00"
var myTimeZone = "+09:00"

var myStartTime = new Date(myStartDate + myStartTime + ":00.000" + myTimeZone);
var myEndTime = new Date(myEndDate + myEndTime + ":00.000" + myTimeZone);
var myRefTime = new Date(myStartDate + "00:00:00.000" + myTimeZone);

function getTimezone() {
  var offset = -(new Date()).getTimezoneOffset()/60;
  return ("UTC" + (offset >= 0 ? "+" : "") + offset);
}

function getLocalTimezone() {
  try {
    return Intl.DateTimeFormat().resolvedOptions().timeZone + " time (" + getTimezone() + ", your browser's time zone)";
  }
  catch(e) {
    return " (" + getTimezone() + ", i.e., your browser's time zone)";
  }
}

function displayTime(dt) {
  var hour = dt.getHours();
  var minute = dt.getMinutes();
  var temp = '' + ((hour < 10) ? '0' : '') + hour;
  temp += ((minute < 10) ? ':0' : ':') + minute;
  return temp;
}

function writeTimeRange(startHour, startMin, endHour, endMin) {
  var oneMin = 1000 * 60;
  var oneHour = oneMin * 60;
  var startTime = new Date(myRefTime.getTime() + startHour * oneHour + startMin * oneMin);
  var endTime = new Date(myRefTime.getTime() + endHour * oneHour + endMin * oneMin);
  document.write(displayTime(startTime));
  document.write(" -- ");
  if (endTime.getDay() != myStartTime.getDay()) {
    document.write(myEndTime.toLocaleDateString('en-US', {month:'short', day:'numeric'}));
	document.write(" ");
  }
  document.write(displayTime(endTime));
  return;
}
</script>


 <body>
    <section class="page-header">
      <h1 class="project-name">International Workshop on</h1>
      <h1 class="project-name">Weakly Supervised Learning 2025</h1>
      <h2 class="project-tagline" style="font-size:175%;">Southeast University; Oct 27 to 29, China Standard Time (UTC+8)</h2>
      <h2 class="project-tagline">&nbsp;</h2>
    </section>

<section class="main-content">
    <center>[ <a href="#program">Program</a>,
			<a href="#registration">Registration</a>,
              <a href="#topics">Topics</a>,
              <a href="#organizers">Organizers</a>,
              <a href="#previous-workshops">Previous Workshops</a> ]</center>

<p>This is an international workshop on weakly supervised learning. The main goal of this workshop is to discuss challenging research topics in weakly supervised learning areas such as semi-supervised learning, positive-unlabeled learning, label noise learning, partial label learning, and self-supervised learning, as well as the foster collaborations among universities and institutes.</p>

 

<h1 id="program">Program</h1>

	<h2>Venue & Date</h2>
        <p><b>Workshop Venue:</b> Lecture Hall, 3A Floor Building 1, SEU National University Science Park 33 Southeast University Road, Jiangning District, Nanjing, China. </p>
		<p><b>Workshop Date:</b> October 27 09:30--17:10, October 28 09:30--17:30, October 29 09:30--12:30 (China Standard Time (UTC+8)).</p>
		<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d6775.96371467414!2d118.8077428!3d31.87991!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x35b58574c0e30583%3A0x7ea0e213e761bd83!2sSoutheast%20University%20National%20University%20Science%20Park%20(Jiangning)!5e0!3m2!1sen!2s!4v1760171307002!5m2!1sen!2s" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
	
		<p><b>Banquet Venue:</b> Youhu Hall, 3rd Floor Holiday Inn Nanjing Shangqinhuai 21 Mozhou East Road, Jiangning District, Nanjing, China.</p>
	    <p><b>Banquet Date:</b> October 28 18:00 - (China Standard Time (UTC+8)).</p>
		<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d1694.1782823142548!2d118.83001!3d31.86971999999999!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x35b58511501da2bf%3A0xb35649e7b20a8387!2zQ2hpbmEsIEppYW5nIFN1IFNoZW5nLCBOYW4gSmluZyBTaGksIEppYW5nIE5pbmcgUXUsIE1vemhvdSBFIFJkLCAyMeWPt-WNl-S6rOS4iuenpua3ruWBh-aXpemFkuW6lyDpgq7mlL_nvJbnoIE6IDIxMTE4OQ!5e0!3m2!1sen!2s!4v1760171873409!5m2!1sen!2s" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>

    <h2>Schedule</h1>
        <p>The workshop will use China Standard Time (UTC+8) for scheduling, and it will be combined with invited talks and contributed talks.</p>
		<p>Online Attending: Zoom 856 7080 2245, psw 2345.</a></p>

<table>
  <thead>
    <tr><th style="width:25ex">Time</th><th>Event</th></tr>
  </thead>
  <tbody>
    <tr><td><b>Octorber 27 (Day 1)</b></td></tr>
	<tr><td></td><td><b>Section Chair</b>: <a href="https://palm.seu.edu.cn/zhangml/" target="_blank">Min-Ling Zhang</td></tr>
    <tr><td>09:30 -- 09:50</td><td><b>Opening and Welcome Remarks</b><br><b>Hosts</b>: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a> (RIKEN/ The University of Tokyo) and <a href="https://palm.seu.edu.cn/xgeng/index.html" target="_blank">Xin Geng </a> (Southeast University)</td></tr>
    <tr><td>09:50 -- 10:35</td><td><b>Title</b>: Beyond Ground-Truth for Discriminative Learning <br><b>Speaker</b>: <a href="https://cv.snu.ac.kr/index.php/~bhhan/" target="_blank">Bohyung Han</a> (Seoul National University)</td></tr>
    <tr><td>10:35 -- 11:15<td><b>Coffee Break</b></td></tr>
    <tr><td>11:15 -- 12:00</td><td><b>Title</b>: High-Resolution Land Cover Products for All-Weather Mapping <br><b>Speaker</b>: <a href="https://researchmap.jp/xiajunshi" target="_blank">Junshi Xia</a> (RIKEN)</td></tr>
    <tr><td>12:00 -- 13:30</td><td><b>Lunch Break</b></td></tr>
	<tr><td></td><td><b>Section Chair</b>: </td></tr>
    <tr><td>13:30 -- 14:15</td><td><b>Title</b>: Network Compression under Imperfect Conditions<br><b>Speaker</b>: <a href="https://gcatnjust.github.io/ChenGong/index.html"  target="_blank">Chen Gong</a> (Shanghai Jiao Tong University)</td></tr>
    <tr><td>14:15 -- 15:00</td><td><b>Title</b>: Principled Learning with Incomplete Category Information: From Imbalanced Recognition to Open-World Understanding<br><b>Speaker</b>: <a href="https://joshuaas.github.io/" target="_blank">Zhiyong Yang</a> (University of Chinese Academic of Science)</td></tr>
    <tr><td>15:00 -- 15:40</td><td><b>Coffee Break</b></td></tr>  
    <tr><td>15:40 -- 16:25</td><td><b>Title</b>: Data Annotation and Synthesis Driven by Large Language Models<br><b>Speaker</b>: <a href="https://hbzju.github.io/">Haobo Wang</a> (Zhejiang University)</td></tr>
    <tr><td>16:25 -- 17:10</td><td><b>Title</b>: Towards Improving Reasoning & Planning Abilities of LLMs with Neuro-Symbolic Methods<br><b>Speaker</b>: <a href="https://www.lamda.nju.edu.cn/guolz/" target="_blank">Lan-Zhe Guo</a> (Nanjing University)</td></tr>
   
    
    <tr><td><b>Octorber 28 (Day 2)</b></td></tr>
	<tr><td></td><td><b>Section Chair</b>: <a href="https://fpfcjdsg.github.io/" target="_blank">Pengfei Fang</td></tr>
    <tr><td>09:30 -- 10:15</td><td><b>Title</b>: The Blessings of Weak Supervision for Training & Inference<br><b>Speaker</b>: <a href="https://akmenon.github.io/" target="_blank">Aditya Krishna Menon (Online)</a> (Google)</td></tr>
    <tr><td>10:15 -- 11:00</td><td><b>Title</b>: -- <br><b>Speaker</b>: <a href="https://www.cse.ust.hk/~jamesk/" target="_blank">James Tin Yau Kwok</a> (Hong Kong University of Science and Technology)</td></tr>
    <tr><td>11:00 -- 11:45</td><td><b>Coffee Break</b></td></tr>
    <tr><td>11:45 -- 12:30</td><td><b>Title</b>: Complementary-Label Learning with Real-World Datasets <br><b>Speaker</b>: <a href="https://maitanha.github.io/" target="_blank">Mai Tan Ha</a> (National Taiwan University)</td></tr>
    <tr><td>12:30 -- 14:00<td><b>Lunch Break</b></td></tr>
	<tr><td></td><td><b>Section Chair</b>: <a href="https://palm.seu.edu.cn/xuning/" target="_blank">Ning Xu</td></tr>
    <tr><td>14:00 -- 14:45</td><td><b>Title</b>: Effective Pre-Trained Models Reuse with Meta Representation<br><b>Speaker</b>: <a href="https://www.lamda.nju.edu.cn/yehj/" target="_blank">Han-Jia Ye</a> (Nanjing University)</td></tr>
    <tr><td>14:45 -- 15:30</td><td><b>Title</b>: Counterfactual Fairness with Partially Known Causal Graph<br><b>Speaker</b>: <a href="https://mingming-gong.github.io/" target="_blank">Mingming Gong</a> (The University of Melbourne / MBZUAI)</td></tr>
    <tr><td>15:30 -- 16:00</td><td><b>Coffee Break</b></td></tr> 
    <tr><td>16:00 -- 16:45</td><td><b>Title</b>: Uncertainty in Optimization: A Primal Approach to Certifying Distributional Robustness <br><b>Speaker</b>: <a href="https://vinuni.edu.vn/people/chu-thi-mai-hong-3/" target="_blank">Chu Thi Mai Hong</a> (VinUniversity)</td></tr>
    <tr><td>16:45 -- 17:30</td><td><b>Title</b>: Exploring Trustworthy Foundation Models: Benchmarking, Finetuning, and Reasoning<br><b>Speaker</b>: <a href="https://bhanml.github.io/"  target="_blank">Bo Han</a> (Hong Kong Baptist University)</td></tr>
    <tr><td>18:00 --</td><td><b>Banquet</b></td></tr>

    <tr><td><b>Octorber 29 (Day 3)</b></td></tr>
	<tr><td></td><td><b>Section Chair</b>: <a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</td></tr>
    <tr><td>09:30 -- 10:15</td><td><b>Title</b>: -- <br><b>Speaker</b>: <a href="https://parnec.nuaa.edu.cn/lisy/" target="_blank">Shao-Yuan Li</a> (Nanjing University of Aeronautics and Astronautics)</td></tr>
    <tr><td>10:15 -- 11:00</td><td><b>Title</b>: Title</b>: Statistics as a Compass for AI Security<br><b>Speaker</b>: <a href="https://fengliu90.github.io/" target="_blank">Feng Liu</a> (The University of Melbourne)</td></tr>
    <tr><td>11:00 -- 11:30</td><td><b>Coffee Break</b></td></tr>
    <tr><td>11:30 -- 12:15</td><td><b>Title</b>: Conditional Diffusion Model Training Meets Imprecise Supervision<br><b>Speaker</b>: <a href="https://wu-dd.github.io/" target="_blank">Dong-Dong Wu</a> (The University of Tokyo)</td></tr>
    <tr><td>12:15 -- 12:30</td><td><b>Closing Remarks and Discussion</b><br><b>Host</b>: <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a> (RIKEN)</td></tr>
  </tbody>
</table>

	
<h1 id="registration">Registration CLOSE</h1>
	<p>Thanks for your support! </p>

	
<h1 id="topics">Topics</h1>

    <h2>Overview</h2>
        <p>Machine learning should not be accessible only to those who can pay. Specifically, modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which require a plethora of well-annotated data. Giant companies have enough money to collect well-annotated data. However, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to <b>weakly supervised learning (WSL)</b>, since WSL does not require such a huge amount of annotated data. We define WSL as the collection of machine learning problem settings and algorithms that share the same goals as supervised learning but can only access to <b>less supervised information</b> than supervised learning. In this workshop, we discuss both theoretical and applied aspects of WSL.</p>

        <p>This workshop is a series of our previous workshops at ACML 2019, SDM 2020, ACML 2020, IJCAI 2021, and ACML 2021. Our particular technical emphasis at this workshop is incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and weak adversarial supervision. Meanwhile, this workshop will also focus on <b>WSL for Science and Social Good</b>, such as WSL for healthcare, WSL for climate change, WSL for remote sensing, and new public WSL datasets regarding the scientific scenarios. With the emergence of foundation models, WSL has gained new momentum: foundation models can enhance WSL through their rich semantic knowledge and powerful representations, while WSL provides efficient solutions for adapting and aligning foundation models with minimal human supervision.</p>

    <h2>Topics of Interest</h2>
        <p>WSL workshop includes (but not limited to) the following topics:</p>
        <ul>
            <li>Algorithms and theories of <b>incomplete supervision</b>, e.g., semi-supervised learning, active learning, and positive-unlabeled learning;</li>
            <li>Algorithms and theories of <b>inexact supervision</b>, e.g., multi-instance learning, complementary learning, and open-set learning;</li>
            <li>Algorithms and theories of <b>inaccurate supervision</b>, e.g., crowdsourced learning and label-noise learning;</li>
            <li>Algorithms and theories of <b>cross-domain supervision</b>, e.g., zero-/one-/few-shot learning, transferable learning, and multi-task learning;</li>
            <li>Algorithms and theories of <b>imperfect demonstration</b>, e.g., inverse reinforcement learning and imitation learning with non-expert demonstrations;</li>
            <li>Algorithms and theories of <b>adversarial</b> weakly-supervised learning, e.g., adversarial semi-supervised learning and adversarial label-noisy learning; </li>
	    <li>Algorithms and theories of <b>self-supervision</b>, e.g., contrastive learning and autoencoder learning; </li>
	    <li>Algorithms and theories of <b>WSL in foundation models</b>, e.g., weak-to-strong paradigm, weak supervision signals for model alignment, and fine-tuning with weak feedback; </li>
	    <li><b>Foundation models for WSL</b>, e.g., leveraging large language/vision models to provide weak supervision signals, and foundation model guided label denoising and sample selection; </li>
            <li>Broad applications of weakly supervised learning in the field of computer science, such as weakly supervised object detection <b>(computer vision)</b>, weakly supervised sequence modeling <b>(natural language processing)</b>, weakly supervised cross-media retrieval <b>(information retrieval)</b>, and weakly supervised cooperation policy learning <b>(multi-agent systems)</b>.</li>
            <li><b>WSL for science and social good</b>, such as WSL for COVID-19, WSL for healthcare, WSL for climate change, and WSL for remote sensing, meanwhile, new public datasets regarding the above WSL research directions (new focus).</li>
        </ul>

    <h2>Further Descriptions</h2>
        <p>The focus of this workshop is six types of weak supervision: incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and weak adversarial supervision, which are briefly introduced below. </p>

	 <ul>
        <li><b>Incomplete supervision</b> considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised learning and positive-unlabeled learning. </li>

        <li><b>Inexact supervision</b> considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, multi-instance learning belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. </li>
        
        <li><b>Inaccurate supervision</b> considers the situation where the supervision information is not always the ground-truth, such as label-noise learning.</li>

        <li><b>Cross-domain supervision</b> considers the situation where the supervision information is scarce or even non-existent in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain. </li>

        <li><b>Imperfect demonstration</b> considers the situation for inverse reinforcement learning and imitation learning, where the agent learns with imperfect or non-expert demonstrations. For example, AlphaGo learns a policy from a sequence of states and actions (expert demonstration). Even if an expert player wins a game, it is not guaranteed that every action in the sequence is optimal.</li>

        <li><b>Weak adversarial supervision</b> considers the situation where weak supervision meets adversarial robustness. Since machine learning models are increasingly deployed in real-world applications, their security attracts more and more attention from both academia and industry. Therefore, many robust learning algorithms aim to prevent various evasion attacks, e.g., adversarial attacks, privacy attacks, model stealing attacks, and so on. However, almost all those robust algorithms (against evasion attacks) implicitly assume the strong supervision signals (no noisy labels in the training data), which hardly meets the requirements in practice. Therefore, when we develop evasion-robust algorithms, it is very practical/urgent to consider the supervision signals are imperfect.</li>

	<li><b>Self-supervision</b> considers the unsupervised situation, and it pre-trains a generic feature representation by autonomously building the pseudo supervision (e.g., the similarity contrast and sample reconstruction) from the raw data, the learned representation can be applied in various downstream tasks such as classification, retrieval, and clustering.</li>
	 

	<li><b>WSL in foundation models</b> considers the critical challenge of efficiently adapting and aligning foundation models to specific tasks and requirements. While foundation models acquire broad knowledge through pre-training on massive unlabeled data, they still face challenges in task-specific alignment, safety constraints, and behavioral refinement. WSL offers theoretical frameworks and practical approaches to achieve these objectives with minimal human supervision, enabling weak-to-strong generalization and efficient fine-tuning through various forms of weak supervision signals (e.g., preferences, rankings, constraints). This paradigm is particularly crucial for developing more trustworthy AI systems.</li>

	<li><b>Foundation models for WSL</b> leverages the rich semantic knowledge and powerful representations learned by foundation models to enhance WSL tasks. The broad knowledge captured by foundation models enables multiple key capabilities: generating diverse forms of weak supervision signals, providing semantic understanding for label reasoning, augmenting training data through knowledge transfer, and improving WSL algorithms through better feature representations and cross-modal correlations. </li></ul>

        <p>Meanwhile, this workshop will <b>continue discussing broad applications of weakly supervised learning in the field of computer science</b>, such as weakly supervised object detection (computer vision), weakly supervised sequence modeling (natural language processing), weakly supervised cross-media retrieval (information retrieval), and weakly supervised cooperation policy learning (multi-agent systems).</p>


<h1 id="organizers">Organizers</h1>
        <h2>General Chairs</h2>
		<p><a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>, RIKEN / The University of Tokyo, Japan.</p>
        	<p><a href="http://palm.seu.edu.cn/xgeng/" target="_blank">Xin Geng</a>, Southeast University, China.</td></tr></p>
        <h2>Program Chairs</h2>
        	<p><a href="https://lvjiaqi77.github.io/" target="_blank">Jiaqi Lv </a>, Southeast University, China.</td></tr></p>
		    <p><a href="https://lfeng1995.github.io/" target="_blank">Lei Feng</a>, Southeast University, China.</p>
        	<p><a href="https://bhanml.github.io/" target="_blank">Bo Han</a>, Hong Kong Baptist University, Hong Kong SAR, China.</p>
        	<p><a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</a>, The University of Sydney, Australia.</p>
        	<p><a href="https://niug1984.github.io/" target="_blank">Gang Niu</a>, RIKEN, Japan.</p>
	<h2>Local Organization Committee (in alphabetical order)</h2>
		    <p><a href="https://palm.seu.edu.cn/qilei/" target="_blank">Lei Qi</a>, Southeast University, China.</p>
        	<p><a href="https://yiguoqiao.github.io/">Yiguo Qiao</a>, Southeast University, China.</p>
		    <p><a href="https://palm.seu.edu.cn/wangjing/" target="_blank">Jing Wang </a>, Southeast University, China.</p>
        	<p><a href="https://palm.seu.edu.cn/xuning/" target="_blank">Ning Xu</a>, Southeast University, China.</p>
	<h2>Organization</h2>
		<h3>Organizing Institution</h3>
		<p>School of Computer Science and Engineering, Southeast University.</p>

		<h3>Supporting Organizations</h3>
		<p>Jiangsu Association of Artificial Intelligence.</p>

<h1 id="previous-workshops">Previous Workshops</h1>
    <p><a href="https://wsl-workshop.github.io/wsl24.html" target="_blank">WSL 2024 Workshop</a>, Brisbane, Australia.</p> 
	<p><a href="https://wsl-workshop.github.io/wsl23.html" target="_blank">WSL 2023 Workshop</a>, Tokyo, Japan.</p> 
	<p><a href="https://wsl-workshop.github.io/acml22.html" target="_blank">ACML2022 WSL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/acml21.html" target="_blank">ACML2021 WSL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/ijcai21.html" target="_blank">IJCAI2021 WSRL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/acml20.html" target="_blank">ACML2020 WSRL Workshop</a>, Online.</p>
    <p><a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">SDM2020 WSUL Workshop</a>, Ohio, United States.</p>
    <p><a href="https://wsl-workshop.github.io/acml19.html" target="_blank">ACML2019 WSL Workshop</a>, Nagoya, Japan.</p>

<footer class="site-footer">
    <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
</footer>
</section>
</body></html>
