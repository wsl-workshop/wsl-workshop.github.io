<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>IJCAI2021 WSRL Workshop</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">IJCAI2021 WSRL Workshop</h1>
      <h2 class="project-tagline">Weakly Supervised Representation Learning Workshop, Aug 22nd, Online</h2>  
    </section>

    <section class="main-content">
<h1 id="topic-summary">Topic Summary</h1>

<p>Machine learning should not be accessible only to those who can pay. Specifically, modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which emphasizes the data representation highly. This learning paradigm is known as representation learning. Specifically, via deep neural networks, learned representations often result in much better performance than can be obtained with hand-designed representations.

It is noted that representation learning normally requires a plethora of well-annotated data. Giant companies have enough money to collect well-annotated data. Nonetheless, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to <strong>weakly supervised representation learning (WSRL)</strong>, since WSRL does not require such a huge amount of annotated data. We define WSRL as the collection of representation learning problem settings and algorithms that share the same goals as supervised representation learning but can only access to <strong>less supervised information</strong> than supervised representation learning. In this workshop, we discuss both theoretical and applied aspects of WSRL. Meanwhile, we will invite qualified submissions to <a href="https://www.springer.com/journal/10994">Machine Learning Journal</a> Special Issue on <a href="https://wsl-workshop.github.io/MLJ_WSRL_CFP.pdf">Weakly Supervised Representation Learning</a>.</p>

<h1 id="topics-of-interest">Topics of Interest</h1>

<p>WSRL workshop includes but not limited to the following topics:</p>

<ul>
  <li>Algorithms and theories of <strong>incomplete supervision</strong>, e.g., semi-supervised representation learning, active representation learning and positive-unlabeled representation learning;</li>
  <li>Algorithms and theories of <strong>inexact supervision</strong>, e.g., multi-instance representation learning and complementary representation learning;</li>
  <li>Algorithms and theories of <strong>inaccurate supervision</strong>, e.g., crowdsourced representation learning and label-noise representation learning;</li>
  <li>Algorithms and theories of <strong>cross-domain supervision</strong>, e.g., zero-/one-/few-shot representation learning, transferable representation learning and multi-task representation leaning;</li>
  <li>Algorithms and theories of <strong>imperfect demonstration</strong>, e.g., inverse reinforcement representation learning and imitation representation learning with non-expert demonstrations;</li>
  <li>Broad applications of weakly-supervised representation learning, such as weakly supervised <strong>object detection</strong>, weakly supervised <strong>sequence modeling</strong>, weakly supervised <strong>cross-media retrieval</strong>, and weakly supervised <strong>medical image segmentation</strong>.</li>
</ul>

<h1 id="topic-description">Topic Description</h1>

<p>The focus of this workshop is five types of weak supervision: incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision and imperfect demonstration. Specifically, incomplete supervision considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised representation learning and positive-unlabeled representation learning. Inexact supervision considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, multi-instance representation learning belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. Inaccurate supervision considers the situation where the supervision information is not always the ground-truth, such as label-noise representation learning.</p>

<p>Cross-domain supervision considers the situation where the supervision information is scarce or even non-existent
in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot representation learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain. Imperfect demonstration considers the situation for inverse reinforcement representation learning and imitation representation learning, where the agent learns with imperfect or non-expert demonstrations. For example, AlphaGo learns a policy from a sequence of states and actions (expert demonstration). Even if an expert player wins a game, it is not guaranteed that every action in the sequence is optimal.</p>

<p>This workshop will discuss the fundamental theory of weakly supervised representation learning. Although theories of weakly supervised statistical learning already exist, extending these results for weakly supervised representation learning is still a challenge. Besides, this workshop also discusses on broad applications of weakly supervised representation learning, such as weakly supervised object detection (computer vision), weakly supervised sequence modeling (natural language processing), weakly supervised cross-media retrieval (information retrieval), and weakly supervised medical image segmentation (healthcare analysis).</p>

<h1 id="submission-guidelines">Submission Guidelines</h1>

<p>Papers should be formatted according to the IJCAI2021 formatting instructions for the Conference Track. The submissions with 2 pages will be considered for the poster, while the submissions with at least 4 pages will be considered for the oral presentation. Workshop submissions and camera ready versions will be handled by CMT. Please submit your paper to <a href="https://cmt3.research.microsoft.com/IJCAIWSRL2021">https://cmt3.research.microsoft.com/IJCAIWSRL2021</a></p>

<p>IJCAI2021-WSRL is a non-archival venue and there will be no published proceedings. The papers will be posted on the workshop website. It will be possible to submit the IJCAI2021-WSRL submissions to other conferences and journals both in parallel to and after
IJCAI2021-WSRL, if they accept such submissions. Besides, we also welcome submissions to IJCAI2021-WSRL that are under review at other conferences and workshops, if they allow concurrent submissions. At least one author from each accepted paper must register for the workshop. Please see the IJCAI 2021 Website for information about registration.</p>

<h1 id="invited-speakers">List of Invited Speakers</h1>

<p><p><a href="http://pages.cs.wisc.edu/~sharonli/">Sharon Li</a>, University of Wisconsin-Madison (confirmed)</p>
<p><a href="https://www.paroma.xyz/">Paroma Varma</a>, Snorkel AI (confirmed)</p>
<p><p><a href="https://cs.nju.edu.cn/liyf/">Yu-Feng Li</a>, Nanjing University (confirmed)</p>
<p><a href="https://ajratner.github.io/">Alex Ratner</a>, University of Washington (confirmed)</p>
<p><p><a href="http://changxu.xyz/">Chang Xu</a>, University of Sydney (confirmed)</p>
<p><a href="http://www.yliuu.com/">Yang Liu</a>, University of California Santa Cruz (confirmed)</p>
<p><a href="http://chunyuan.li/">Chunyuan Li</a>, Microsoft Research, Redmond (confirmed)</p>

<h1 id="tentative-schedule">Schedule and Zoom Recordings</h1>

<p>The workshop will use <a href="https://time.is/UTC">UTC time</a> for scheduling, and it will be combined with invited talks, contributed talks, and panel discussions.</p>
<!-- <p>The workshop is totally free online. Check our workshop recordings</p> -->

<table>
  <thead>
    <tr>
      <th>Time (UTC)</th>
      <th>Event</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>00:00-00:05am</td>
      <td><strong>Opening Ceremony</strong></td>
    </tr>
	<tr>
      <td>&nbsp;</td>
      <td><strong>Host</strong>: Masashi Sugiyama</td>
    </tr>
    <tr>
      <td>00:05-00:35am</td>
      <td><strong>Invited Talk 1</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Programmatic Supervision for Data-Centric AI</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Alex Ratner</td>
    </tr><tr>
      <td>00:35-00:45am</td>
      <td><strong>Contributed Talk 1</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Autoencoding Slow Representations for Semi-supervised Data Efficient Regression</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Oliver Struckmeier, Kshitij Tiwari, and Ville Kyrki</td>
    </tr>
    <tr>
      <td>00:45-1:15am</td>
      <td><strong>Invited Talk 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Uncovering the Unknowns of Deep Neural Networks: Challenges and Opportunities</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Sharon Li</td>
    </tr>
    <tr>
      <td>1:15-1:25am</td>
      <td><strong>Contributed Talk 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: A Weakly-Supervised Depth Estimation Network Using Attention Mechanism</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Fang Gao, wang jiabao, Jun Yu, yao xiong wang, and Feng Shuang</td>
    </tr>
	    <tr>
      <td>1:25-1:55am</td>
      <td><strong>Invited Talk 3</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: TBD</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Paroma Varma</td>
    </tr>
	<tr>
      <td>1:55-2:05am</td>
      <td><strong>Contributed Talk 3</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Semi-Supervised Deep Ensembles for Blind Image Quality Assessment</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Authors</strong>: Zhihua Wang, Dingquan Li, and Kede Ma</td>
    </tr>
	    <tr>
      <td>2:05-2:35am</td>
      <td><strong>Invited Talk 4</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Learning from Noisy Labels: Some Lessons and Challenges</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Yang Liu</td>
    </tr><tr>
      <td>2:35-2:45am</td>
      <td><strong>Contributed Talk 4</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Zhaowei Zhu, Yiwen Song, and Yang Liu</td>
    </tr>
    <tr>
      <td>2:45-3:15am</td>
      <td><strong>Invited Talk 5</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: TBD</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Chang Xu</td>
    </tr>
    <tr>
      <td>3:15-3:25am</td>
      <td><strong>Contributed Talk 5</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Learning from Crowds with Sparse and Imbalanced Annotations</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Authors</strong>: Ye Shi, Shao-Yuan Li, and Sheng-Jun Huang</td>
    </tr>
	    <tr>
      <td>3:25-3:55am</td>
      <td><strong>Invited Talk 6</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: OOD Example and New Label under Weakly Supervised Scenario</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Yu-Feng Li</td>
    </tr>
	<tr>
      <td>3:55-4:05am</td>
      <td><strong>Contributed Talk 6</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Property-aware Adaptive Relation Networks for Molecular Property Prediction</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Authors</strong>: Yaqing Wang, Abulikemu Abuduweili, and Dejing Dou</td>
    </tr>
	<td>4:05-4:25am</td>
      <td><strong>Invited Talk 7</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Efficient Self-supervised Vision Transformers for Representation Learning
</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Chunyuan Li</td>
    </tr>
	<tr>
      <td>4:25-4:50am</td>
      <td><strong>Panel Discussion & Concluding Remark</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Host</strong>: Bo Han</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Guests</strong>: TBD</td>
    </tr>
	    <tr>
      <td>4:50-5:50am</td>
      <td><strong>Poster Session</strong></td>
    </tr>
	  <tr>
      <td>&nbsp;</td>
      <td><strong>GatherTown</strong>: TBD</td>
    </tr>
  </tbody>
</table>

<!-- <h1 id="Best-paper">Best Paper Awards (alphabetic ordering)</h1>

<p>Nan Lu, Tianyi Zhang, Gang Niu, and Masashi Sugiyama. RIKEN AIP & The University of Tokyo, Japan.</p>

<p>Melanie F. Pradier, Weiwei Pan, Jiayu Yao, Soumya Ghosh, and Finale Doshi-Velez. Harvard University, USA.</p>

<p>Hansi Yang, and Quanming Yao. Tsinghua University & 4Paradigm, China.</p> -->

<h1 id="accepted-papers">Accepted Papers</h1>	
<div>
<ul>
	   <li><p>
           Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels [<a href="https://arxiv.org/abs/2102.05291">PDF</a>] <br>
           Zhaowei Zhu, Yiwen Song, Yang Liu<br>
           </p></li>  
	
		   <li><p>
           Decoupling Representation and Classifier for Noisy Label Learning [<a href="https://arxiv.org/abs/2011.08145">PDF</a>] <br>
           Hui Zhang, Quanming Yao<br>
           </p></li>  
	
		   <li><p>
           TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation [<a href="https://arxiv.org/abs/2106.06326">PDF</a>] <br>
           Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Bo Han <br>
           </p></li>  

		   <li><p>
           An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for Noisy Labels [<a href="https://arxiv.org/abs/2107.02347">PDF</a>] <br>
           Yong Wen, Marcus Kalander, Chanfei Su, Lujia Pan<br>
           </p></li>  
	
	
		   <li><p>
           When Optimizing f-Divergence is Robust with Label Noise [<a href="https://arxiv.org/abs/2011.03687">PDF</a>] <br>
           Jiaheng Wei, Yang Liu<br>
           </p></li>  
                  
	
		   <li><p>
            Semi-Supervised Deep Ensembles for Blind Image Quality Assessment [<a href="https://arxiv.org/abs/2106.14008">PDF</a>] <br>
          Zhihua Wang, Dingquan Li, Kede Ma <br>
           </p></li>  
                  
	
		   <li><p>
           ANOMALYMAXQ: Anomaly-Structured Maximization to Query in Attributed Networks [<a href="">PDF</a>] <br>
           Xinyue Zhang, Nannan Wu, Zixu Zhen, Wenjun Wang<br>
           </p></li>  
                  
	
		   <li><p>
           Learning from Self-Discrepancy via Multiple Co-teaching for Cross-Domain Person Re-Identification [<a href="https://arxiv.org/pdf/2104.02265.pdf">PDF</a>] <br>
           Suncheng Xiang, Yuzhuo Fu, Mengyuan Guan, Ting Liu<br>
           </p></li>  
                  
	
		   <li><p>
           Autoencoding Slow Representations for Semi-supervised Data Efficient Regression [<a href="https://arxiv.org/abs/2012.06279">PDF</a>] <br>
           Oliver Struckmeier, Kshitij Tiwari, Ville Kyrki<br>
           </p></li>  
                  
	
		   <li><p>
           Learning from Multiple Annotators by Incorporating Instance Features [<a href="http://arxiv.org/abs/2106.15146">PDF</a>] <br>
           Jingzheng Li, Hailong Sun, Jiyi Li, Zhijun Chen, Renshuai Tao, Yufei Ge<br>
           </p></li>  
                  
	
		   <li><p>
           Automated Label Generation for Time Series Classification with Representation Learning: Reduction of Label Cost for Training [<a href="https://arxiv.org/abs/2107.05458">PDF</a>] <br>
           Soma Bandyopadhyay, Anish Datta, Arpan Pal<br>
           </p></li>  
                  
	
		   <li><p>
           Semi-supervised Learning for Marked Temporal Point Processes [<a href="https://www.semion.io/doc/semi-supervised-learning-for-marked-temporal-point-processes">PDF</a>] <br>
           Shivshankar Mr Reddy, Anand Vir Singh Chauhan, Maneet Singh, Karamjit Singh<br>
           </p></li>  
                  
	
		   <li><p>
           A Weakly-Supervised Depth Estimation Network Using Attention Mechanism [<a href="https://arxiv.org/ftp/arxiv/papers/2107/2107.04819.pdf">PDF</a>] <br>
           Fang Gao, Jiabao Wang, Jun Yu, Yao Xiong Wang, Feng Shuang<br>
           </p></li>  	

	
		   <li><p>
          Class-Agnostic Segmentation Loss and Its Application to Salient Object Detection and Segmentation  [<a href="https://arxiv.org/abs/2010.14793">PDF</a>] <br>
          Angira Sharma, Naeemullah Khan, Muhammad Mubashar, Ganesh Sundaramoorthi, Philip Torr <br>
           </p></li>  
                  
	
			   <li><p>
           Graph Self Supervised Learning: the BT, the HSIC, and the VICReg [<a href="https://arxiv.org/pdf/2105.12247.pdf">PDF</a>] <br>
           Sayan Nag<br>
           </p></li>  
                   

                  
	
		   <li><p>
           BiSTF: Bilateral-Branch Self-Training Framework for Domain-Shifted and Imbalanced Semi-Supervised Large-scale Fine-Grained Recognition [<a href="https://arxiv.org/abs/2107.06768">PDF</a>] <br>
           Hao Chang, Guochen Xie, Jun Yu, Qiang Ling<br>
           </p></li>  
                  
	
		   <li><p>
           Learning from Crowds with Sparse and Imbalanced Annotations [<a href="https://arxiv.org/pdf/2107.05039.pdf">PDF</a>] <br>
           Ye Shi, Shao-Yuan Li, Sheng-Jun Huang <br>
           </p></li>  
                  
	
		   <li><p>
          Positive-Unlabeled Classification under Class-Prior Shift: A Prior-invariant Approach Based on Density Ratio Estimation [<a href="https://arxiv.org/abs/2107.05045">PDF</a>] <br>
           Shota Nakajima, Masashi Sugiyama<br>
           </p></li>  
                  
	
		   <li><p>
          Self Training with Ensemble of Teacher Models  [<a href="https://arxiv.org/abs/2107.08211">PDF</a>] <br>
          Soumyadeep Ghosh, Sanjay Kumar, Janu Verma, Awanish Kumar <br>
           </p></li>  
                  
	
		   <li><p>
           Color Variants Identification in Fashion e-commerce via Contrastive Self-Supervised Representation Learning [<a href="">PDF</a>] <br>
          Ujjal Kr Dutta, Sandeep Repakula, Maulik Parmar, Abhinav Ravi <br>
           </p></li>  
                  
	
		   <li><p>
           Pseudo-labelling Enhanced Media Bias Detection [<a href="">PDF</a>] <br>
          Qin Ruan, Brian Mac Namee, Ruihai Dong <br>
           </p></li>  
                  
	
		   <li><p>
          Property-aware Adaptive Relation Networks for Molecular Property Prediction [<a href="">PDF</a>] <br>
          Yaqing Wang, Abulikemu Abuduweili, Dejing Dou  <br>
           </p></li>  
                  
	
		   <li><p>
           Context-Conditional Adaptation for Recognizing Unseen Classes in Unseen Domains [<a href="">PDF</a>] <br>
           Puneet Mangla, Shivam Chandhok, Vineeth Balasubramanian, Fahad Shahbaz Khan<br>
           </p></li>  
                  
	
		   <li><p>
           Learn from Anywhere: Rethinking Generalized Zero-Shot Learning with Limited Supervision [<a href="">PDF</a>] <br>
          Gaurav Bhatt, Shivam Chandhok, Vineeth N Balasubramanian <br>
           </p></li>  
                  
	
		   <li><p>
           Box-Adapt: Domain-Adaptive Medical ImageSegmentation using Bounding Box Supervision [<a href="">PDF</a>] <br>
          Yanwu Xu, Mingming Gong, Shaoan Xie, Kayhan Batmanghelich  <br>
           </p></li>  
                  
	
		   <li><p>
           Towards an Interpretable Latent Space in Structured Models for Video Prediction [<a href="">PDF</a>] <br>
           Rushil Gupta, Vishal Sharma, Yash Jain, Yitao Liang, Guy Van den Broeck, Parag Singla<br>
           </p></li>  
                  
	

                  
                  
</ul>
</div>

<h1 id="important-dates">Important Dates</h1>

<p>Submission Deadline: June 15th, 2021 (2nd Round)</p>

<p>Acceptance Notifications: June 25th, 2021</p>

<h1 id="organizers">Organizers</h1>

<p><a href="https://bhanml.github.io/">Bo Han</a>, Hong Kong Baptist University, Hong Kong SAR, China.</p>

<p><a href="https://tongliang-liu.github.io/">Tongliang Liu</a>, The University of Sydney, Australia.</p>

<p><a href="http://www.cse.ust.hk/~qyaoaa/">Quanming Yao</a>, Tsinghua University / 4Paradigm Inc., China.</p>

<p><a href="https://mingming-gong.github.io/">Mingming Gong</a>, The University of Melbourne, Australia.</p>

<p><a href="https://gcatnjust.github.io/ChenGong/index.html">Chen Gong</a>, Nanjing University of Science and Technology, China.</p>

<p><a href="https://niug1984.github.io/">Gang Niu</a>, RIKEN, Japan.</p>

<p><a href="https://www.uts.edu.au/staff/ivor.tsang">Ivor W. Tsang</a>, University of Technology Sydney, Australia.</p>

<p><a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">Masashi Sugiyama</a>, RIKEN / University of Tokyo, Japan.</p>

<h1 id="sponsors">Sponsors</h1>

<p>Several awards are kindly sponsored by 4Paradigm Inc.</p>

<h1 id="previous-workshops">Previous Workshops</h1><p>
<a href="https://wsl-workshop.github.io/acml20.html">ACML2020 WSRL Workshop</a>, Online.</p>
<p><a href="https://wsl-workshop.github.io/sdm20.html">SDM2020 WSUL Workshop</a>, Ohio, United States.</p>
<p><a href="https://wsl-workshop.github.io/acml19.html">ACML2019 WSL Workshop</a>, Nagoya, Japan.</p>

      <footer class="site-footer">
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </section>

</body></html>

