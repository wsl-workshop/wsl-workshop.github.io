<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SDM workshop</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h2 id="welcome-to-sdm2020-weakly-supervised-and-unsupervised-learning-workshop">Welcome to SDM2020 Weakly-supervised and Unsupervised Learning Workshop</h2>
<h1 id="topic-summary">Topic Summary</h1>
<p>Modern data mining is migrating to the era of complex models (e.g., deep neural networks), which require a plethora of data to train. However, most existing data mining algorithms rely heavily on supervisory label information. As dataset sizes grow bigger, obtaining labels is becoming more and more laborious and expensive. Giant companies have enough money to collect well-annotated data. However, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to weakly-supervised and unsupervised learning (WSUL), since that it does not require such a huge amount of annotated data and that it is relatively easy to collect a large amount of unannotated data. We therefore propose a workshop for researchers from different fields of data mining that face this problem to discuss this issue and foster further research advances in this direction.</p>
<p>We define WSUL as the collection of learning problem settings and algorithms that share the similar goals as supervised learning but can only access to <strong>less or even no supervised information</strong> than supervised learning.<br>
In this workshop, we discuss both theoretical and applied aspects of WSUL, which includes but not limited to the following topics:</p>
<ul>
<li>Theories, algorithms, and applications of  <strong>no supervision</strong>, e.g., clustering, generative adversarial nets, variational autoencoders;</li>
<li>Theories, algorithms, and applications of <strong>incomplete supervision</strong>, e.g., dealing with semi-supervised data or positive-unlabeled data;</li>
<li>Theories, algorithms, and applications of <strong>inexact supervision</strong>, e.g., dealing with similarity/dissimilarity data and complementary information;</li>
<li>Theories, algorithms, and applications of <strong>inaccurate supervision</strong>, e.g., crowdsourcing and dealing with noisy labels;</li>
<li>Theories, algorithms, and applications of <strong>cross-domain supervision</strong>, e.g., domain adaptation and zero-/one-/few-shot learning.</li>
</ul>
<p>The focus of this workshop is five types of supervision: no supervision, incomplete supervision, inexact supervision, inaccurate supervision, and cross-domain supervision. Specifically, no supervision considers problems in which no data have ground-truth labels. Incomplete supervision considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised data and positive-unlabeled data. Inexact supervision considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, the multi-instance learning setting belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. Inaccurate supervision considers the situation where the supervision information is not always the ground-truth, such as learning with noisy labels. Cross-domain supervision considers the situation where the supervision information is scarce or even non-existent in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain.</p>
<p>This workshop will discuss the fundamental theories of weakly-supervised and unsupervised learning. Although theories of statistical weakly-supervised and unsupervised learning already exist, extending these results for deep weakly-supervised and unsupervised learning is still a challenge. Besides, this workshop also discusses on broad applications of weakly-supervised and unsupervised learning, such as mining text, web &amp; social media, analyzing finance data, genomics &amp; bioinformatics, and recommendation.</p>
<h1 id="format-tentative-schedule">Format (Tentative Schedule)</h1>
<p>The workshop will be combined with invited talks, accepted presentations, and informal discussions. We prefer a one-day long workshop.</p>

<table>
<thead>
<tr>
<th>Time</th>
<th>Event</th>
</tr>
</thead>
<tbody>
<tr>
<td>09:00-09:15</td>
<td><strong>Opening Ceremony</strong></td>
</tr>
<tr>
<td></td>
<td>Session 1: Incomplete supervision, inexact supervision and inaccurate supervision</td>
</tr>
<tr>
<td>09:15-10:15</td>
<td><strong>Keynote Talk 1</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Speaker</strong>: Lingfei Wu, (IBM T. J. Watson Research Center; confirmed)</td>
</tr>
<tr>
<td>10:15-11:15</td>
<td><strong>Keynote Talk 2</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Speaker</strong>: Jiayu Zhou, (Michgan State University; confirmed)</td>
</tr>
<tr>
<td>11:15-11:25</td>
<td><strong>Contributed Talk 1</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: TBD</td>
</tr>
<tr>
<td>11:25-11:35</td>
<td><strong>Contributed Talk 2</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: TBD</td>
</tr>
<tr>
<td>11:35-11:45</td>
<td><strong>Contributed Talk 3</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: TBD</td>
</tr>
<tr>
<td>11:45-12:45</td>
<td><strong>Poster session 1 / Coffee break</strong></td>
</tr>
<tr>
<td>11:45-12:45</td>
<td><strong>12:45-14:30 / Lunch break</strong></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Session 2: No supervision and Cross-domain supervision</td>
</tr>
<tr>
<td>14:30-15:30</td>
<td><strong>Keynote Talk 3</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Speaker</strong>: Kayhan Batmanghelich, (University of Pittsburgh; confirmed)</td>
</tr>
<tr>
<td>15:30-16:30</td>
<td><strong>Keynote Talk 4</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Speaker</strong>: Zhangyang Wang, (Texas A&amp;M University; confirmed)</td>
</tr>
<tr>
<td>16:30-16:40</td>
<td><strong>Keynote Talk 5</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: Wei-Lun Chao, (Ohio State University; confirmed)</td>
</tr>
<tr>
<td>16:40-16:50</td>
<td><strong>Contributed Talk 4</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: TBD</td>
</tr>
<tr>
<td>16:50-17:00</td>
<td><strong>Contributed Talk 5</strong></td>
</tr>
<tr>
<td></td>
<td><strong>Title</strong>: TBD</td>
</tr>
<tr>
<td></td>
<td><strong>Authors</strong>: TBD</td>
</tr>
<tr>
<td>17:00-18:00</td>
<td><strong>Poster session 2 / Coffee break</strong></td>
</tr>
</tbody>
</table><h1 id="target-audience">Target Audience</h1>
<p>The target audience consists of researchers and practitioners who are working or interested in the problems, theories, algorithms, and applications in the area of weakly supervised and unsupervised data mining. The attendees of SDM2020 are the major audience of the proposed workshop. We will also distribution the call-for-workshop-paper information to attract attendees from a broad spectrum of related communities.</p>
<h1 id="list-of-potential-participants">List of Potential Participants</h1>
<p>Mingming Gong (University of Melbourne)<br>
Chunyuan Li (Microsoft Research Redmond)<br>
Tongliang Liu (University of Sydney)<br>
Bo Han (RIKEN-AIP / HKBU)<br>
Quanming Yao (4Paradigm)<br>
Gang Niu (RIKEN-AIP)<br>
Kun Zhang (Carnegie Mellon University)<br>
Masashi Sugiyama (RIKEN-AIP / University of Tokyo)<br>
Lingfei Wu (IBM T. J. Watson Research Center)<br>
Kayhan Batmanghelich (University of Pittsburgh)<br>
Jiayu Zhou (Michigan State University)<br>
Zhangyang Wang (Texas A&amp;M University)<br>
Wei-Lun Chao (Ohio State University)</p>
<h1 id="previous-workshops">Previous Workshops</h1>
<p>Partial organizers are organizing a weakly-supervised learning workshop in Asian Conference on Machine Learning (ACML) 2019: <a href="https://wsl-workshop.github.io/">https://wsl-workshop.github.io/</a>. Meanwhile, they have successfully raised 6000 USD to support several awards in this workshop. The number of attendees and paper submissions is around 30-40 in local ACML conference; while they believe that in global conference SDM, they can call more attendees and paper submissions. Besides, they have sufficient experience to organize and propagate this workshop, which can also enhance the academic and social impact of SDM conference.</p>
<h1 id="organizers-contact-details">Organizers Contact Details</h1>
<p>Mingming Gong (University of Melbourne).</p>
<ul>
<li>Email: <a href="mailto:mingming.gong@unimelb.edu.au">mingming.gong@unimelb.edu.au</a></li>
<li>Homepage: <a href="https://mingming-gong.github.io/">https://mingming-gong.github.io/</a></li>
<li>Scholar: <a href="https://scholar.google.com.au/citations?user=6BmiCJIAAAAJ&amp;hl=en">https://scholar.google.com.au/citations?user=6BmiCJIAAAAJ&amp;hl=en</a></li>
</ul>
<p>Chunyuan Li (Microsoft Research Redmond).</p>
<ul>
<li>Email: <a href="mailto:chunyuan.li@hotmail.com">chunyuan.li@hotmail.com</a></li>
<li>Homepage: <a href="http://chunyuan.li/">http://chunyuan.li/</a></li>
<li>Scholar: <a href="https://scholar.google.com/citations?user=Zd7WmXUAAAAJ&amp;hl=en">https://scholar.google.com/citations?user=Zd7WmXUAAAAJ&amp;hl=en</a></li>
</ul>
<p>Tongliang Liu (University of Sydney).</p>
<ul>
<li>Email: <a href="mailto:tongliang.liu@sydney.edu.au">tongliang.liu@sydney.edu.au</a></li>
<li>Homepage: <a href="https://tongliang-liu.github.io/">https://tongliang-liu.github.io/</a></li>
<li>Scholar: <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&amp;hl=en">https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&amp;hl=en</a></li>
</ul>
<p>Bo Han (RIKEN-AIP / HKBU)</p>
<ul>
<li>Email: <a href="mailto:bo.han@riken.jp">bo.han@riken.jp</a></li>
<li>Homepage: <a href="https://bhanml.github.io/">https://bhanml.github.io/</a></li>
<li>Scholar: <a href="https://scholar.google.com/citations?user=nTNjqHwAAAAJ&amp;hl=en">https://scholar.google.com/citations?user=nTNjqHwAAAAJ&amp;hl=en</a></li>
</ul>
<p>Quanming Yao (4Paradigm)</p>
<ul>
<li>Email: <a href="mailto:yaoquanming@4paradigm.com">yaoquanming@4paradigm.com</a></li>
<li>Homepage: <a href="http://www.cse.ust.hk/~qyaoaa/">http://www.cse.ust.hk/~qyaoaa/</a></li>
<li>Scholar: <a href="https://scholar.google.com/citations?user=6PEbAiYAAAAJ&amp;hl=en">https://scholar.google.com/citations?user=6PEbAiYAAAAJ&amp;hl=en</a></li>
</ul>
<p>Gang Niu (RIKEN-AIP)</p>
<ul>
<li>Email: <a href="mailto:gang.niu@riken.jp">gang.niu@riken.jp</a></li>
<li>Homepage: <a href="https://niug1984.github.io/">https://niug1984.github.io/</a></li>
<li>Scholar: <a href="https://scholar.google.com/citations?user=HOkcy00AAAAJ&amp;hl=en">https://scholar.google.com/citations?user=HOkcy00AAAAJ&amp;hl=en</a></li>
</ul>
<p>Kun Zhang (Carnegie Melllon University)</p>
<ul>
<li>Email: <a href="mailto:kunz1@cmu.edu">kunz1@cmu.edu</a></li>
<li>Homepage: <a href="http://www.andrew.cmu.edu/user/kunz1/index.html">http://www.andrew.cmu.edu/user/kunz1/index.html</a></li>
<li>Scholar: <a href="https://scholar.google.com.au/citations?user=RGoypN4AAAAJ&amp;hl=en">https://scholar.google.com.au/citations?user=RGoypN4AAAAJ&amp;hl=en</a></li>
</ul>
<p>Masashi Sugiyama (RIKEN-AIP / University of Tokyo)</p>
<ul>
<li>Email: <a href="mailto:sugi@k.u-tokyo.ac.jp">sugi@k.u-tokyo.ac.jp</a></li>
<li>Homepage: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">http://www.ms.k.u-tokyo.ac.jp/sugi/</a></li>
<li>Scholar: <a href="https://scholar.google.com/citations?user=GkYIrlIAAAAJ&amp;hl=en">https://scholar.google.com/citations?user=GkYIrlIAAAAJ&amp;hl=en</a></li>
</ul>
<h1 id="organizers--bio">Organizers  Bio</h1>
<p><a href="https://mingming-gong.github.io/">Mingming Gong</a>, University of Melbourne, Australia.<br>
Mingming Gong is a Lecturer (Assistant Professor) in data science with the School of Mathematics and Statistics, University of Melbourne. His research interests include causal inference, machine learning, and visual analytics. He has authored and co-authored 30+ research papers including NeurIPS, ICML, UAI, AISTATS, CVPR, ICCV, ECCV, and AAAI. Gong has studied how the causal generative process of data benefit learning in non-standard settings, such as weakly-supervised learning and transfer learning . He also studies principles and methods to infer causal models from various kinds of observational data, including under-sampled time series, data with measurement error, nonstationary and heterogeneous data.</p>
<p><a href="http://chunyuan.li/">Chunyuan Li</a>, Microsoft Research Redmond, USA.<br>
Chunyuan Li is a senior researcher with Microsoft Research, Redmomd. He received his Ph.D. degree from Duke University. His interests are deep learning and probabilistic modeling, with applications to natural language processing and computer vision. The results are published in 40+ papers, e.g., NeurIPS, ICML, ICLR, CVPR, AISTATS, ACL and EMNLP.</p>
<p><a href="https://tongliang-liu.github.io/">Tongliang Liu</a>, University of Sydney, Australia.<br>
Tongliang Liu is currently a Lecturer (Assistant Professor) with the School of Computer Science in the Faculty of Engineering, and also a core member in the UBTECH Sydney AI Centre, at the University of Sydney (USYD). He received his PhD degree in 2016 from the University of Technology Sydney (UTS). While pursuing his PhD, he visited the Department of Economics and Business at the University of Pompeu Fabra for half a year. Before joining USYD in 2017, he was a lecturer with the Centre of AI at UTS. His research interests include statistical machine learning, computer vision, and data mining. He has authored and co-authored 60+ research papers including TPAMI, TNNLS, TIP, ICML, NeurIPS, KDD, CVPR, ECCV, AAAI, IJCAI, and ICME.</p>
<p><a href="https://bhanml.github.io/">Bo Han</a>, RIKEN-AIP/HKBU, Japan/Hongkong.<br>
Bo Han is a postdoc fellow at RIKEN-AIP, advised by Masashi Sugiyama. He will join Hong Kong Baptist University as an assistant professor. He pursued his Ph.D. degree at University of Technology Sydney, advised by Ivor W. Tsang and Ling Chen. His current research interests lie in machine learning, deep learning and artificial intelligence. His long-term goal is to develop intelligent systems, which can learn from a massive volume of complex (e.g., weakly-supervised and adversarial) data (e.g, single-/multi-label, ranking, domain, similarity, graph and demonstration) automatically. He has published 16 journal articles and conference papers, including MLJ, TNNLS, TKDE articles and NeurIPS, ICML, IJCAI papers. He has served as program committes of NeurIPS, ICML, ICLR, AISTATS, UAI, AAAI, and ACML. He received UTS Research Publication Award. He co-organized ACML 2019 weakly-supervised learning workshop and challenge.</p>
<p><a href="https://protect-au.mimecast.com/s/NqcYC6X1PysKW2yYtLOYlP?domain=cse.ust.hk">Quanming Yao</a>, 4Paradigm Inc., Hong Kong.<br>
Quanming Yao is a research scientist of 4Paradigm Inc,  which is one of the world’s leading AI technology and service providers for industrial applications. He has board interests in machine learning and its applications, including optimization for machine learning, automated machine learning (AutoML),  recommender system and learning with noisy labels. He received his Ph.D. degree in Computer Science and Engineering Department of Hong Kong University of Science and Technology in 2018. He is author and co-author of 21 papers, which are published in many prestige venues, e.g., ICML, NeurIPS, JMLR, and TPAMI. He was also a Google fellowship winner in 2016. He also organized recent NeurIPS 2018 and PAKDD 2019 AutoML competitions.</p>
<p><a href="https://niug1984.github.io/">Gang Niu</a>, RIKEN-AIP, Japan.<br>
Gang Niu is currently a research scientist at RIKEN Center for Advanced Intelligence Project. He obtained his master and doctor degrees in computer science from Nanjing University and Tokyo Institute of Technology in 2010 and 2013 respectively. Before joining RIKEN AIP, he was a senior RD engineer at Baidu NLP and then an assistant professor at the University of Tokyo. He has published more than 30 journal articles and conference papers, including 2 JMLR, 10 NeurIPS (1 oral and 1 spotlight), and 10 ICML papers. He has served as an area chair of NeurIPS 2019, ICML 2019, AISTATS 2019 and AAAI 2019.</p>
<p><a href="http://www.andrew.cmu.edu/user/kunz1/">Kun Zhang</a>, Carnegie Mellon University, USA.<br>
Kun Zhang is an associate professor in the philosophy department and an affiliate faculty member in the machine learning department at Carnegie Mellon University, USA, and a senior research scientist at Max Planck Institute for Intelligent Systems, Germany. His research interests lie in machine learning and artificial intelligence, especially in causal discovery and causality-based learning. He develops methods for automated causal discovery from various kinds of data, investigate learning problems, especially transfer learning, weakly-supervised learning, concept learning, and deep learning, from a causal view, and study philosophical foundations of causation and various machine learning tasks. He is an associate editor of three international journals and has served as an area chair or senior program committee member for major conferences in machine learning or artificial intelligence, including NeurIPS, UAI, ICML, AISTATS, AAAI, and IJCAI. He has organized various academic activities to foster interdisciplinary research in causality.</p>
<p><a href="https://protect-au.mimecast.com/s/YJIIC81ZRASRkVYpTROoNj?domain=ms.k.u-tokyo.ac.jp">Masashi Sugiyama</a>, RIKEN / University of Tokyo, Japan.<br>
Masashi Sugiyama is a full professor at the University of Tokyo and the Director of the RIKEN Center for Advanced Intelligence Project (AIP), which is a national research center founded in 2016 in Japan. In the RIKEN-AIP Center, he created 50 machine learning &amp; artificial intelligence research teams ranging from fundamental theory to real-world applications and ethical issues, and hired over 700 researchers and students from over the world. He has published over 300 papers in NeurIPS, ICML, AISTATS, NeCo, JMLR, etc. He has served as a Program Co-Chair and General Co-Chair for NeurIPS2015 and NeurIPS2016 and is a Program Co-Chair for AISTATS2019.</p>
</div>
</body>

</html>
